# continue_training:
data:
  trainset: /data3/easton/data/CALLHOME_Multilingual/jsons/train
  devset: /data3/easton/data/CALLHOME_Multilingual/jsons/dev/ja_dev.json
  vocab_phone: /home/easton/projects/OpenASR/egs/callhome_hkust/data/callhome.IPA
  vocab_char: /home/easton/projects/OpenASR/egs/callhome_hkust/data/vocab_ja.char
  maxlen: 200
  fetchworker_num: 4
model:
  type: CIF_MIX
  add_eos: True
  add_blk: False
  signal:
    feature_type: offline
    spec_aug:
        freq_mask_num: 2
        freq_mask_width: 27
        time_mask_num: 2
        time_mask_width: 40
  encoder:
    type: Transformer
    sub:
      type: ConvV2
      layer_num: 1
    input_dim: 80
    d_model: 512
    nhead: 8
    dim_feedforward: 2048
    activation: "glu"
    num_layers: 4
    dropout_rate: 0.1
  assigner:
    d_model: 512
    n_layers: 3
    w_context: 3
    dropout: 0.1
  decoder:
    type: TransformerDecoder
    vocab_size: -1 # derived by tokenizer
    d_model: 512
    nhead: 8
    num_layers: 4
    encoder_dim: 512
    dim_feedforward: 2048
    activation: "glu"
    dropout_rate: 0.1
training:
    label_type: feat_phone_char
    batch_frames: 10000
    multi_gpu: False
    exp_dir: exp/cif_mix
    print_inteval: 50
    num_epoch: 80
    accumulate_grad_batch: 8
    init_lr: 0.1
    optimtype: adam
    grad_max_norm: 50.
    label_smooth: 0.1
    lambda_qua: 0.1
    lambda_ctc: 1.0
    num_last_ckpt_keep: 10
    lr_scheduler:
        type: warmup_transformer
        warmup_step: 10000
        d_model: 512
